{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 1 : CREATING TRAINING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:39: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:39: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__        __   _                            _          _____              \n",
      "\\ \\      / /__| | ___ ___  _ __ ___   ___  | |_ ___   |  ___|_ _  ___ ___ \n",
      " \\ \\ /\\ / / _ \\ |/ __/ _ \\| '_ ` _ \\ / _ \\ | __/ _ \\  | |_ / _` |/ __/ _ \\\n",
      "  \\ V  V /  __/ | (_| (_) | | | | | |  __/ | || (_) | |  _| (_| | (_|  __/\n",
      "   \\_/\\_/ \\___|_|\\___\\___/|_| |_| |_|\\___|  \\__\\___/  |_|  \\__,_|\\___\\___|\n",
      "                                                                          \n",
      " ____                            _ _   _             \n",
      "|  _ \\ ___  ___ ___   __ _ _ __ (_) |_(_) ___  _ __  \n",
      "| |_) / _ \\/ __/ _ \\ / _` | '_ \\| | __| |/ _ \\| '_ \\ \n",
      "|  _ <  __/ (_| (_) | (_| | | | | | |_| | (_) | | | |\n",
      "|_| \\_\\___|\\___\\___/ \\__, |_| |_|_|\\__|_|\\___/|_| |_|\n",
      "                     |___/                           \n",
      " ____                                      \n",
      "|  _ \\ _ __ ___   __ _ _ __ __ _ _ __ ___  \n",
      "| |_) | '__/ _ \\ / _` | '__/ _` | '_ ` _ \\ \n",
      "|  __/| | | (_) | (_| | | | (_| | | | | | |\n",
      "|_|   |_|  \\___/ \\__, |_|  \\__,_|_| |_| |_|\n",
      "                 |___/                     \n",
      "\n",
      "\n",
      "\n",
      "\u001b[32mThe WebCam is being opened\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-5aa0c5ec24eb>:39: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[31mCollecting Samples Complete\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from termcolor import colored\n",
    "import pyfiglet\n",
    "import os\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import smtplib\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.base import MIMEBase\n",
    "from email import encoders\n",
    "\n",
    "  \n",
    "# SETTING ENV VARIABLES FOR PYTHON\n",
    "os.environ['EMAIL_USER'] = 'freakdroid24@gmail.com'\n",
    "os.environ['EMAIL_PASSWORD'] = 'akashfd240'\n",
    "  \n",
    "EMAIL_USER = os.environ.get(\"EMAIL_USER\")\n",
    "EMAIL_PASS = os.environ.get(\"EMAIL_PASSWORD\")\n",
    "receiver_address = \"akashtikkiwal240@gmail.com\"\n",
    "\n",
    "a = \"Welcome to Face Recognition Program\"\n",
    "st = pyfiglet.figlet_format(a)\n",
    "print(st)\n",
    "\n",
    "# Load HAAR face classifier\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Load functions\n",
    "def face_extractor(img):\n",
    "    # Function detects faces and returns the cropped face\n",
    "    # If no face detected, it returns the input image\n",
    "    \n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    if faces is ():\n",
    "        return None\n",
    "    \n",
    "    # Crop all faces found\n",
    "    for (x,y,w,h) in faces:\n",
    "        cropped_face = img[y:y+h, x:x+w]\n",
    "\n",
    "    return cropped_face\n",
    "\n",
    "# Initialize Webcam\n",
    "print(\"\\n\")\n",
    "print(colored(\"The WebCam is being opened\",'green'))\n",
    "cap = cv2.VideoCapture(0)\n",
    "count = 0\n",
    "\n",
    "# Collect 100 samples of your face from webcam input\n",
    "while True:\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if face_extractor(frame) is not None:\n",
    "        count += 1\n",
    "        face = cv2.resize(face_extractor(frame), (200, 200))\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Save file in specified directory with unique name\n",
    "        file_name_path = './faces/users/' + str(count) + '.jpg'\n",
    "        cv2.imwrite(file_name_path, face)\n",
    "\n",
    "        # Put count on images and display live count\n",
    "        cv2.putText(face, str(count), (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "        cv2.imshow('Face Cropper', face)\n",
    "        \n",
    "    else:\n",
    "        print(colored(\"Face not found\",'green'))\n",
    "        pass\n",
    "\n",
    "    if cv2.waitKey(1) == 13 or count == 100: #13 is the Enter Key\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows() \n",
    "print(\"\\n\")\n",
    "print(colored(\"Collecting Samples Complete\",'red'))\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 : TRAINING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mMODEL IS BEING TRAINED\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[34mModel trained sucessefully\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "print(colored(\"MODEL IS BEING TRAINED\",'red'))\n",
    "print(\"\\n\")\n",
    "# Get the training data we previously made\n",
    "data_path = './faces/users/'\n",
    "onlyfiles = [f for f in listdir(data_path) if isfile(join(data_path, f))]\n",
    "\n",
    "# Create arrays for training data and labels\n",
    "Training_Data, Labels = [], []\n",
    "\n",
    "# Open training images in our datapath\n",
    "# Create a numpy array for training data\n",
    "for i, files in enumerate(onlyfiles):\n",
    "    image_path = data_path + onlyfiles[i]\n",
    "    images = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    Training_Data.append(np.asarray(images, dtype=np.uint8))\n",
    "    Labels.append(i)\n",
    "\n",
    "# Create a numpy array for both training data and labels\n",
    "Labels = np.asarray(Labels, dtype=np.int32)\n",
    "\n",
    "\n",
    "\n",
    "# Initialize facial recognizer\n",
    "# model = cv2.face.createLBPHFaceRecognizer()\n",
    "# NOTE: For OpenCV 3.0 use cv2.face.createLBPHFaceRecognizer()\n",
    "# pip install opencv-contrib-python\n",
    "#model = cv2.createLBPHFaceRecognizer()\n",
    "\n",
    "akash_model  = cv2.face.LBPHFaceRecognizer_create()\n",
    "# Let's train our model \n",
    "akash_model.train(np.asarray(Training_Data), np.asarray(Labels))\n",
    "print(colored(\"Model trained sucessefully\",'blue'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 : RUN OUR FACIAL RECOGNITION PROGRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:68: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:68: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<ipython-input-10-de189cb4eca3>:68: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mData is being sent to the hardware !!!\u001b[0m\n",
      "\u001b[31mImage saved!\u001b[0m\n",
      "\u001b[34mData is being sent to the hardware !!!\u001b[0m\n",
      "\u001b[31mFace Recognition Successful\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[32mAnd \n",
      " The trained model is92% accurate\u001b[0m\n",
      "\u001b[31mImage saved!\u001b[0m\n",
      "\u001b[32m\t\t\t=================EMAIL HAS BEEN SENT=================\u001b[0m\n",
      "\u001b[34mData is being sent to the hardware !!!\u001b[0m\n",
      "\u001b[31mFace Recognition Successful\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[32mAnd \n",
      " The trained model is92% accurate\u001b[0m\n",
      "\u001b[31mImage saved!\u001b[0m\n",
      "\u001b[34mData is being sent to the hardware !!!\u001b[0m\n",
      "\u001b[31mFace Recognition Successful\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[32mAnd \n",
      " The trained model is93% accurate\u001b[0m\n",
      "\u001b[31mImage saved!\u001b[0m\n",
      "\u001b[34mData is being sent to the hardware !!!\u001b[0m\n",
      "\u001b[31mFace Recognition Successful\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[32mAnd \n",
      " The trained model is93% accurate\u001b[0m\n",
      "\u001b[31mImage saved!\u001b[0m\n",
      "\u001b[34mData is being sent to the hardware !!!\u001b[0m\n",
      "\u001b[31mFace Recognition Successful\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[32mAnd \n",
      " The trained model is93% accurate\u001b[0m\n",
      "\u001b[31mImage saved!\u001b[0m\n",
      "\u001b[34mData is being sent to the hardware !!!\u001b[0m\n",
      "\u001b[31mImage saved!\u001b[0m\n",
      "\u001b[34mData is being sent to the hardware !!!\u001b[0m\n",
      "\u001b[31mFace Recognition Successful\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[32mAnd \n",
      " The trained model is92% accurate\u001b[0m\n",
      "\u001b[31mImage saved!\u001b[0m\n",
      "\u001b[34mData is being sent to the hardware !!!\u001b[0m\n",
      "\u001b[31mImage saved!\u001b[0m\n",
      "\u001b[34mData is being sent to the hardware !!!\u001b[0m\n",
      "\u001b[31mFace Recognition Successful\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[32mAnd \n",
      " The trained model is92% accurate\u001b[0m\n",
      "\u001b[31mImage saved!\u001b[0m\n",
      "\u001b[34mData is being sent to the hardware !!!\u001b[0m\n",
      "\u001b[31mFace Recognition Successful\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[32mAnd \n",
      " The trained model is92% accurate\u001b[0m\n",
      "\u001b[31mImage saved!\u001b[0m\n",
      "\u001b[34mCamera OFF !!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import serial\n",
    "import time\n",
    "\n",
    "\n",
    "msg = MIMEMultipart()\n",
    "msg['Subject'] = \"SECURITY UPDATE : Who is there?\"\n",
    "msg['From'] = EMAIL_USER\n",
    "msg['To'] = receiver_address\n",
    "\n",
    "#msg.set_content('Here is the image of the face recognized !')\n",
    "s = smtplib.SMTP('smtp.gmail.com', 587)\n",
    "s.starttls()\n",
    "s.login(EMAIL_USER, EMAIL_PASS)\n",
    "\n",
    "\n",
    "\n",
    "def img_save1():\n",
    "    img_resized = cv2.resize(image,(256,256))\n",
    "    img_resized = cv2.imwrite(filename='AT.jpg', img=img_resized)\n",
    "    print(colored(\"Image saved!\",'red'))\n",
    "    img = os.path.basename('AT.jpg')\n",
    "    img_final = img\n",
    "    #msg.set_content('Here is the image of the face recognized !')\n",
    "    filename = img_final\n",
    "    body1 = \"Its Akash face found in facial recoginition\"\n",
    "    msg.attach(MIMEText(body1, 'plain'))\n",
    "    attachment = open(img_final, \"rb\")\n",
    "    p = MIMEBase('application', 'octet-stream')\n",
    "    p.set_payload((attachment).read())\n",
    "    encoders.encode_base64(p)\n",
    "    p.add_header('Content-Disposition', \"attachment; filename= %s\" % filename)\n",
    "    msg.attach(p)\n",
    "    \n",
    "   \n",
    "    \n",
    "def img_save2():\n",
    "    img_resized = cv2.resize(image,(256,256))\n",
    "    img_resized = cv2.imwrite(filename='Intruder.jpg', img=img_resized)\n",
    "    print(colored(\"Image saved!\",'red'))\n",
    "    img_final = os.path.basename('Intruder.jpg')\n",
    "    img_final = img\n",
    "    filename = img_final\n",
    "    body2 = \"Its the face of some intruder found in facial recoginition\"\n",
    "    msg.attach(MIMEText(body2, 'plain'))\n",
    "    attachment = open(img_final, \"rb\")\n",
    "    p = MIMEBase('application', 'octet-stream')\n",
    "    p.set_payload((attachment).read())\n",
    "    encoders.encode_base64(p)\n",
    "    p.add_header('Content-Disposition', \"attachment; filename= %s\" % filename)\n",
    "    msg.attach(p)\n",
    "    \n",
    "    \n",
    "# Define the serial port and baud rate.\n",
    "# Ensure the 'COM#' corresponds to what was seen in the Windows Device Manager\n",
    "arduinoData = serial.Serial('COM5',9600)\n",
    "time.sleep(2)\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "def face_detector(img, size=0.5):\n",
    "    \n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    if faces is ():\n",
    "        return img, []\n",
    "    \n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,255,0),3)\n",
    "        roi = img[y:y+h, x:x+w]\n",
    "        roi = cv2.resize(roi, (200, 200))\n",
    "    return img, roi\n",
    "\n",
    "\n",
    "# Open Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    image, face = face_detector(frame)\n",
    "    \n",
    "    try:\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Pass face to prediction model\n",
    "        # \"results\" comprises of a tuple containing the label and the confidence value\n",
    "        results = akash_model.predict(face)\n",
    "       \n",
    "        \n",
    "        if results[1] < 500:\n",
    "            confidence = int( 100 * (1 - (results[1])/400) )\n",
    "            acc = 'And \\n The trained model is'  + str(confidence) + '% accurate'\n",
    "            display_string = \"Face Recognition Successful\"\n",
    "        \n",
    "        cv2.putText(image, display_string, (100, 120), cv2.FONT_HERSHEY_COMPLEX, 1, (255,120,150), 2)\n",
    "        \n",
    "        if confidence > 90:\n",
    "            cv2.putText(image, \"It's Akash\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "            cv2.imshow('Face Recognition Program', image )\n",
    "            print(colored(\"Data is being sent to the hardware !!!\",'blue'))\n",
    "            time.sleep(1) \n",
    "            arduinoData.write(b'1')\n",
    "            print(colored(display_string,'red'))\n",
    "            print(\"\\n\")\n",
    "            print(colored(acc,'green'))\n",
    "            img_save1()\n",
    "            text1 = msg.as_string()\n",
    "            s.sendmail(EMAIL_USER, receiver_address, text1)\n",
    "            s.quit()\n",
    "            print(colored(\"\\t\\t\\t=================EMAIL HAS BEEN SENT=================\",'green'))\n",
    "            \n",
    "            \n",
    "            \n",
    "#             \n",
    "           \n",
    "            #os.system(\"chrome https://www.google.com\")\n",
    "            #break\n",
    "         \n",
    "        else:\n",
    "            cv2.putText(image, \"I dont know, Who are you?\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "            cv2.imshow('Face Recognition', image )\n",
    "            print(colored(\"Data is being sent to the hardware !!!\",'blue'))\n",
    "            time.sleep(1)\n",
    "            arduinoData.write(b'2')\n",
    "            img_save2()\n",
    "            text2 = msg.as_string()\n",
    "            s.sendmail(EMAIL_USER, receiver_address, text2)\n",
    "            s.quit()\n",
    "            print(colored(\"\\t\\t\\t=================EMAIL HAS BEEN SENT=================\",'green'))\n",
    "            \n",
    "    \n",
    "        \n",
    "            \n",
    "\n",
    "    except:\n",
    "        cv2.putText(image, \"No Face Found\", (220, 120) , cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.putText(image, \"Looking for face\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.imshow('Face Recognition', image )\n",
    "        pass\n",
    "        \n",
    "    if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "        break\n",
    "        \n",
    "        \n",
    "cap.release()\n",
    "print(colored(\"Camera OFF !!\",'blue'))\n",
    "cv2.destroyAllWindows()  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
